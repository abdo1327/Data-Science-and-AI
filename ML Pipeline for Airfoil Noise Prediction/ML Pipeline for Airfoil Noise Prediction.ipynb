{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbaIhXOEr_Iq"
      },
      "source": [
        "## Build an ML Pipeline for Airfoil noise prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abBRJv22r_Iy"
      },
      "source": [
        "## Scenario\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR4I73rmr_Iz"
      },
      "source": [
        "You are a data engineer at an aeronautics consulting company. Your company prides itself in being able to efficiently design airfoils for use in planes and sports cars. Data scientists in your office need to work with different algorithms and data in different formats. While they are good at Machine Learning, they count on you to be able to do ETL jobs and build ML pipelines. In this project you will use the modified version of the NASA Airfoil Self Noise dataset. You will clean this dataset, by dropping the duplicate rows, and removing the rows with null values. You will create an ML pipe line to create a model that will predict the SoundLevel based on all the other columns. You will evaluate the model and towards the end you will persist the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vd5k6u-r_Iz"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "In this 4 part assignment you will:\n",
        "\n",
        "- Part 1 Perform ETL activity\n",
        "  - Load a csv dataset\n",
        "  - Remove duplicates if any\n",
        "  - Drop rows with null values if any\n",
        "  - Make transformations\n",
        "  - Store the cleaned data in parquet format\n",
        "- Part 2 Create a  Machine Learning Pipeline\n",
        "  - Create a machine learning pipeline for prediction\n",
        "- Part 3 Evaluate the Model\n",
        "  - Evaluate the model using relevant metrics\n",
        "- Part 4 Persist the Model\n",
        "  - Save the model for future production use\n",
        "  - Load and verify the stored model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAATckK_r_I0"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "In this lab you will be using dataset(s):\n",
        "\n",
        " - The original dataset can be found here NASA airfoil self noise dataset. https://archive.ics.uci.edu/dataset/291/airfoil+self+noise\n",
        "\n",
        " - This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDJp1SEqr_I0"
      },
      "source": [
        "Diagram of an airfoil. - For informational purpose\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKGJ22fYr_I1"
      },
      "source": [
        "![Airfoil with flow](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_with_flow.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZezsgLSr_I1"
      },
      "source": [
        "Diagram showing the Angle of attack. - For informational purpose\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yEsoHojr_I1"
      },
      "source": [
        "![Airfoil angle of attack](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_angle_of_attack.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdFbnKpJr_I1"
      },
      "source": [
        "## Before you Start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJgMxctUr_I1"
      },
      "source": [
        "Before you start attempting this project it is highly recommended that you finish the practice project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYflldtlr_I2"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sOM-a46r_I2"
      },
      "source": [
        "For this lab, we will be using the following libraries:\n",
        "\n",
        "*   [`PySpark`](https://spark.apache.org/docs/latest/api/python/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01) for connecting to the Spark Cluster\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F-Yr3PTr_I2"
      },
      "source": [
        "### Installing Required Libraries\n",
        "\n",
        "Spark Cluster is pre-installed in the Skills Network Labs environment. However, you need libraries like pyspark and findspark to\n",
        " connect to this cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fajW6d7sr_I2"
      },
      "source": [
        "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "s9LkI1b3r_I3"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark==3.1.2 -q\n",
        "!pip install findspark -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYq9-lwOr_I3"
      },
      "source": [
        "### Importing Required Libraries\n",
        "\n",
        "_We recommend you import all required libraries in one place (here):_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "fpf6y6X3r_I4"
      },
      "outputs": [],
      "source": [
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# FindSpark simplifies the process of using Apache Spark with Python\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1751lMt7r_I4"
      },
      "source": [
        "## Part 1 - Perform ETL activity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucb5EbXor_I5"
      },
      "source": [
        "### Task 1 - Import required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "7a99JJ-vr_I5"
      },
      "outputs": [],
      "source": [
        "#your code goes here\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.pipeline import PipelineModel\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-jEPNE8r_I5"
      },
      "source": [
        "### Task 2 - Create a spark session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "cYTr618pr_I5"
      },
      "outputs": [],
      "source": [
        "#Create a SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Final Project\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-owQ0Eu4r_I5"
      },
      "source": [
        "### Task 3 - Load the csv file into a dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6hEqqtor_I5"
      },
      "source": [
        "Download the data file.\n",
        "\n",
        "NOTE : Please ensure you use the dataset below and not the original dataset mentioned above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "9njN6r4zr_I5",
        "outputId": "b646bafb-55c6-4bb7-c14b-e88d16838ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-08 21:05:53--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60682 (59K) [text/csv]\n",
            "Saving to: ‘NASA_airfoil_noise_raw.csv’\n",
            "\n",
            "NASA_airfoil_noise_ 100%[===================>]  59.26K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-08 21:05:53 (32.9 MB/s) - ‘NASA_airfoil_noise_raw.csv’ saved [60682/60682]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipcxq0Q_r_I6"
      },
      "source": [
        "Load the dataset into the spark dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "20P9lPdgr_I6"
      },
      "outputs": [],
      "source": [
        "# Load the dataset that you have downloaded in the previous task\n",
        "\n",
        "df = spark.read.csv(\"NASA_airfoil_noise_raw.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtxE2kfxr_I6"
      },
      "source": [
        "### Task 4 - Print top 5 rows of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "NjNGjlQFr_I6",
        "outputId": "02b2ec10-1622-427c-99dd-a9c1e4d3197f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(Frequency=800, AngleOfAttack=0.0, ChordLength=0.3048, FreeStreamVelocity=71.3, SuctionSideDisplacement=0.00266337, SoundLevel=126.201),\n",
              " Row(Frequency=1000, AngleOfAttack=0.0, ChordLength=0.3048, FreeStreamVelocity=71.3, SuctionSideDisplacement=0.00266337, SoundLevel=125.201),\n",
              " Row(Frequency=1250, AngleOfAttack=0.0, ChordLength=0.3048, FreeStreamVelocity=71.3, SuctionSideDisplacement=0.00266337, SoundLevel=125.951),\n",
              " Row(Frequency=1600, AngleOfAttack=0.0, ChordLength=0.3048, FreeStreamVelocity=71.3, SuctionSideDisplacement=0.00266337, SoundLevel=127.591),\n",
              " Row(Frequency=2000, AngleOfAttack=0.0, ChordLength=0.3048, FreeStreamVelocity=71.3, SuctionSideDisplacement=0.00266337, SoundLevel=127.461)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#your code goes here\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8GbNLDAr_I6"
      },
      "source": [
        "### Task 6 - Print the total number of rows in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lRRrSSvpr_I6",
        "outputId": "c9b5c10f-6b87-4aa7-ad21-02e6dece6eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1522\n"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "rowcount1 = df.count()\n",
        "print(rowcount1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEwFEwsOr_I7"
      },
      "source": [
        "### Task 7 - Drop all the duplicate rows from the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "MXl8RtWHr_I7"
      },
      "outputs": [],
      "source": [
        "df = df.dropDuplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKnQYzMSr_I7"
      },
      "source": [
        "### Task 8 - Print the total number of rows in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "0V23IBz0r_I7",
        "outputId": "72f96e0b-1e43-436c-b582-1ccd2ace144c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 9:======================================================>(197 + 3) / 200]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "\n",
        "rowcount2 = df.count()\n",
        "print(rowcount2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boPiiQXwr_I7"
      },
      "source": [
        "### Task 9 - Drop all the rows that contain null values from the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "S9u58XFvr_JI"
      },
      "outputs": [],
      "source": [
        "df=df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBB0US8tr_JI"
      },
      "source": [
        "### Task 10 - Print the total number of rows in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "2dC_tQ4Rr_JI",
        "outputId": "8ddbd9eb-e9ad-4989-9d2d-c935baec27ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 12:================================================>     (180 + 8) / 200]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "\n",
        "rowcount3 = df.count()\n",
        "print(rowcount3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwvPb-Cor_JJ"
      },
      "source": [
        "### Task 11 - Rename the column \"SoundLevel\" to \"SoundLevelDecibels\"Drop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "sqdSorXvr_JJ"
      },
      "outputs": [],
      "source": [
        "# your code goes here\n",
        "\n",
        "df = df.withColumnRenamed(\"SoundLevel\",\"SoundLevelDecibels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmQZCCt1r_JJ"
      },
      "source": [
        "### Task 12 - Save the dataframe in parquet formant, name the file as \"NASA_airfoil_noise_cleaned.parquet\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "XT4IrhCHr_JJ",
        "outputId": "a8d5cba2-8650-4004-c6ce-04d82f0122b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 15:>                                                       (0 + 8) / 200]24/01/08 21:11:16 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "24/01/08 21:11:16 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 84.47% for 8 writers\n",
            "24/01/08 21:11:16 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
            "Scaling row group sizes to 96.54% for 7 writers\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# your code goes here\n",
        "\n",
        "df.write.parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE7XwhQ3r_JJ"
      },
      "source": [
        "#### Part 1 - Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i17aTDwzr_JJ"
      },
      "source": [
        "\n",
        "Run the code cell below.<br>\n",
        "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
        "If the code throws up any errors, go back and review the code you have written.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "b4gWlXngr_JJ",
        "outputId": "7be1a4c0-84c9-4bd9-fbe7-2c36a1c7a764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part 1 - Evaluation\n",
            "Total rows =  1522\n",
            "Total rows after dropping duplicate rows =  1503\n",
            "Total rows after dropping duplicate rows and rows with null values =  1499\n",
            "New column name =  SoundLevelDecibels\n",
            "NASA_airfoil_noise_cleaned.parquet exists : True\n"
          ]
        }
      ],
      "source": [
        "print(\"Part 1 - Evaluation\")\n",
        "\n",
        "print(\"Total rows = \", rowcount1)\n",
        "print(\"Total rows after dropping duplicate rows = \", rowcount2)\n",
        "print(\"Total rows after dropping duplicate rows and rows with null values = \", rowcount3)\n",
        "print(\"New column name = \", df.columns[-1])\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"NASA_airfoil_noise_cleaned.parquet exists :\", os.path.isdir(\"NASA_airfoil_noise_cleaned.parquet\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJwYvJmur_JK"
      },
      "source": [
        "## Part - 2 Create a  Machine Learning Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-WBPx_Cr_JK"
      },
      "source": [
        "### Task 1 - Load data from \"NASA_airfoil_noise_cleaned.parquet\" into a dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "urEBzbBVr_JK"
      },
      "outputs": [],
      "source": [
        "#your code goes here\n",
        "\n",
        "df = spark.read.parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eiLv-Fqr_JK"
      },
      "source": [
        "### Task 2 - Print the total number of rows in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "_UUsCfCGr_JK",
        "outputId": "7bb72f28-1514-4d27-8280-a63e3dd24260"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 19:==================================================>       (7 + 1) / 8]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1499\n",
            "Columns: ['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacement', 'SoundLevelDecibels']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "\n",
        "rowcount4 = df.count()\n",
        "print(rowcount4)\n",
        "\n",
        "columns = df.columns\n",
        "print(\"Columns: {}\".format(columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxsBQxwBr_JK"
      },
      "source": [
        "### Task 3 - Define the VectorAssembler pipeline stage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyyiYCOxr_JL"
      },
      "source": [
        "Stage 1 - Assemble the input columns into a single column \"features\". Use all the columns except SoundLevelDecibels as input features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Fvsrkj23r_JL"
      },
      "outputs": [],
      "source": [
        "#your code goes here\n",
        "assembler = VectorAssembler(inputCols=['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacement'], outputCol=\"features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGTCgFQ0r_JM"
      },
      "source": [
        "### Task 4 - Define the StandardScaler pipeline stage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3lOtSjor_JM"
      },
      "source": [
        "Stage 2 - Scale the \"features\" using standard scaler and store in \"scaledFeatures\" column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "wHaUFTHgr_JM"
      },
      "outputs": [],
      "source": [
        "#your code goes here\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Aukta-Vr_JN"
      },
      "source": [
        "### Task 5 - Define the StandardScaler pipeline stage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99Z6ASKAr_JN"
      },
      "source": [
        "Stage 3 - Create a LinearRegression stage to predict \"SoundLevelDecibels\"\n",
        "\n",
        "**Note:You need to use the scaledfeatures retreived in the previous step.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "N7i-gOMSr_JN",
        "outputId": "31872508-efb7-4de7-9207-ac13f101a4bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinearRegression_b9ed31c54308\n"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"SoundLevelDecibels\")\n",
        "print(lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkgHn4ZCr_JN"
      },
      "source": [
        "### Task 6 - Build the pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBysLVwNr_JN"
      },
      "source": [
        "Build a pipeline using the above three stages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Dxa8Y2tIr_JN"
      },
      "outputs": [],
      "source": [
        "#your code goes here\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler, scaler, lr])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABhOAgpir_JO"
      },
      "source": [
        "### Task 7 - Split the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "yqKaa96Ur_JO",
        "outputId": "4bfc54be-b33f-44bd-b2b8-a84899c39440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets with 70:30 split.\n",
        "# set the value of seed to 42\n",
        "# the above step is very important. DO NOT set the value of seed to any other value other than 42.\n",
        "\n",
        "#your code goes here\n",
        "\n",
        "(trainingData, testingData) = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "print(\"Done\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opLuCQ7Rr_JO"
      },
      "source": [
        "### Task 8 - Fit the pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "bNK5iRB8r_JP",
        "outputId": "6bfeb1b3-f851-4819-e621-1c4e781f8c24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/01/08 21:28:05 WARN util.Instrumentation: [d42576a4] regParam is zero, which might cause numerical instability and overfitting.\n",
            "[Stage 24:>                                                         (0 + 8) / 8]24/01/08 21:28:09 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
            "24/01/08 21:28:09 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
            "24/01/08 21:28:09 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
            "24/01/08 21:28:09 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Fit the pipeline using the training data\n",
        "# your code goes here\n",
        "\n",
        "pipelineModel = pipeline.fit(trainingData)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngm6IyVgr_JP"
      },
      "source": [
        "#### Part 2 - Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2yJ1Zl3r_JP"
      },
      "source": [
        "\n",
        "Run the code cell below.<br>\n",
        "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
        "If the code throws up any errors, go back and review the code you have written.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "QIXs4KRqr_JR",
        "outputId": "2ee61af5-1398-4e6d-9b87-28fcb595a5fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part 2 - Evaluation\n",
            "Total rows =  1499\n",
            "Pipeline Stage 1 =  VectorAssembler\n",
            "Pipeline Stage 2 =  StandardScaler\n",
            "Pipeline Stage 3 =  LinearRegression\n",
            "Label column =  SoundLevelDecibels\n"
          ]
        }
      ],
      "source": [
        "print(\"Part 2 - Evaluation\")\n",
        "print(\"Total rows = \", rowcount4)\n",
        "ps = [str(x).split(\"_\")[0] for x in pipeline.getStages()]\n",
        "\n",
        "print(\"Pipeline Stage 1 = \", ps[0])\n",
        "print(\"Pipeline Stage 2 = \", ps[1])\n",
        "print(\"Pipeline Stage 3 = \", ps[2])\n",
        "\n",
        "print(\"Label column = \", lr.getLabelCol())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "888WfIhhr_JS"
      },
      "source": [
        "## Part 3 - Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RabSCan-r_JU"
      },
      "source": [
        "### Task 1 - Predict using the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "2DNGrVzjr_JU"
      },
      "outputs": [],
      "source": [
        "# Make predictions on testing data\n",
        "# your code goes here\n",
        "\n",
        "predictions = pipelineModel.transform(testingData)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvBUNmiSr_JW"
      },
      "source": [
        "### Task 2 - Print the MSE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "RsKRKVBgr_JX",
        "outputId": "cb3d5df7-6972-47ee-83be-27287ab72d3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 31:==================================================>       (7 + 1) / 8]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22.5937540713487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mse\")\n",
        "mse = evaluator.evaluate(predictions)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtvBcQwOr_JX"
      },
      "source": [
        "### Task 3 - Print the MAE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "feViwnT8r_JX",
        "outputId": "eed1f441-b6d8-4984-e80a-c40d91e8bb9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 33:===========================================>              (6 + 2) / 8]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.7336902294630927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mae\")\n",
        "mae = evaluator.evaluate(predictions)\n",
        "print(mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE-uaBEqr_JY"
      },
      "source": [
        "### Task 4 - Print the R-Squared(R2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lqNz3pJtr_JY",
        "outputId": "605a54cc-a996-43c2-fc88-c5a3984cd33b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 35:==================================================>       (7 + 1) / 8]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.542601650868908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#your code goes here\n",
        "\n",
        "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"r2\")\n",
        "r2 = evaluator.evaluate(predictions)\n",
        "print(r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbSTFK7Dr_JY"
      },
      "source": [
        "#### Part 3 - Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL8tAGoXr_JY"
      },
      "source": [
        "\n",
        "Run the code cell below.<br>\n",
        "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
        "If the code throws up any errors, go back and review the code you have written.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "OJho5dNOr_JZ",
        "outputId": "6f6d25ff-270b-4170-fdab-f0687b6b879d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part 3 - Evaluation\n",
            "Mean Squared Error =  22.59\n",
            "Mean Absolute Error =  3.73\n",
            "R Squared =  0.54\n",
            "Intercept =  132.6\n"
          ]
        }
      ],
      "source": [
        "print(\"Part 3 - Evaluation\")\n",
        "\n",
        "print(\"Mean Squared Error = \", round(mse,2))\n",
        "print(\"Mean Absolute Error = \", round(mae,2))\n",
        "print(\"R Squared = \", round(r2,2))\n",
        "\n",
        "lrModel = pipelineModel.stages[-1]\n",
        "\n",
        "print(\"Intercept = \", round(lrModel.intercept,2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwySHTIWr_JZ"
      },
      "source": [
        "## Part 4 - Persist the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AptCxVg4r_JZ"
      },
      "source": [
        "### Task 1 - Save the model to the path \"Final_Project\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "AdkBToAfr_JZ",
        "outputId": "b374552d-ba68-4b83-c874-e1df930296e5"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute '_jvm'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_635/1850004227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the pipeline model as \"Final_Project\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# your code goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpipelineModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final_Project\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/spark-2.4.3/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mallStagesAreJava\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipelineSharedReadWrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckStagesForJava\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallStagesAreJava\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mJavaMLWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPipelineModelWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/spark-2.4.3/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJavaMLWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/spark-2.4.3/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_to_java\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mjava_stages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mjava_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/spark-2.4.3/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_to_java\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mJava\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mequivalent\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/spark-2.4.3/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transfer_params_to_java\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_defaults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mpair_defaults_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_defaults_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_jvm'"
          ]
        }
      ],
      "source": [
        "# Save the pipeline model as \"Final_Project\"\n",
        "# your code goes here\n",
        "pipelineModel.write().save(\"Final_Project\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er0wSOvfr_Ja"
      },
      "source": [
        "### Task 2 - Load the model from the path \"Final_Project\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "m-Ul9a3lr_Ja",
        "outputId": "ea2bfa86-517f-4fce-dbe0-6e0ea39558ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Load the pipeline model you have created in the previous step\n",
        "loadedPipelineModel = PipelineModel.load(\"Final_Project\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S1arLr7r_Ja"
      },
      "source": [
        "### Task 3 - Make predictions using the loaded model on the testdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "QICgCcGVr_Jb"
      },
      "outputs": [],
      "source": [
        "# Use the loaded pipeline model and make predictions using testingData\n",
        "predictions = loadedPipelineModel.transform(testingData)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSo-bchbr_Jb"
      },
      "source": [
        "### Task 4 - Show the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "SjAyrgzsr_Jb",
        "outputId": "3b528e69-1bde-4629-b910-ba8639ce4a42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 57:>                                                         (0 + 1) / 1]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+------------------+\n",
            "|SoundLevelDecibels|        prediction|\n",
            "+------------------+------------------+\n",
            "|           127.315|123.64344009624709|\n",
            "|           119.975| 123.4869578861485|\n",
            "|           121.783|124.38983849684239|\n",
            "|           127.224|121.44706993294264|\n",
            "|           122.229|125.68312652454149|\n",
            "|           122.754|119.00135887553695|\n",
            "|           127.564|126.52607365319822|\n",
            "|           126.149|124.72369322766558|\n",
            "|           120.076|129.24665689814103|\n",
            "|           138.123| 130.6295186434797|\n",
            "|           127.314| 127.1308953309623|\n",
            "|           130.715|125.89163510250563|\n",
            "|           129.367| 129.3042308895184|\n",
            "|           122.905| 129.9451290107517|\n",
            "|           127.127|128.10022579415545|\n",
            "|           127.417|126.28072873047742|\n",
            "|           128.698|122.06234864411724|\n",
            "|           131.073|122.38819030163245|\n",
            "|           135.368|125.76877819819667|\n",
            "|           124.514|125.43708134590958|\n",
            "+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#show top 5 rows from the predections dataframe. Display only the label column and predictions\n",
        "#your code goes here\n",
        "predictions.select(\"SoundLevelDecibels\",\"prediction\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OgCcCV8r_Jb"
      },
      "source": [
        "#### Part 4 - Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCt6ebJIr_Jb"
      },
      "source": [
        "\n",
        "Run the code cell below.<br>\n",
        "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
        "If the code throws up any errors, go back and review the code you have written.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "MEtNxGMmr_Jb",
        "outputId": "a12d0579-1f76-4880-8b6f-5360b6667354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Part 4 - Evaluation\n",
            "Number of stages in the pipeline =  3\n",
            "Coefficient for Frequency is -0.0013\n",
            "Coefficient for AngleOfAttack is -0.4111\n",
            "Coefficient for ChordLength is -36.1575\n",
            "Coefficient for FreeStreamVelocity is 0.1019\n",
            "Coefficient for SuctionSideDisplacement is -135.2067\n"
          ]
        }
      ],
      "source": [
        "print(\"Part 4 - Evaluation\")\n",
        "\n",
        "loadedmodel = loadedPipelineModel.stages[-1]\n",
        "totalstages = len(loadedPipelineModel.stages)\n",
        "inputcolumns = loadedPipelineModel.stages[0].getInputCols()\n",
        "\n",
        "print(\"Number of stages in the pipeline = \", totalstages)\n",
        "for i,j in zip(inputcolumns, loadedmodel.coefficients):\n",
        "    print(f\"Coefficient for {i} is {round(j,4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjap6acxr_Jc"
      },
      "source": [
        "### Stop Spark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "RG2A-IoIr_Jc"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}